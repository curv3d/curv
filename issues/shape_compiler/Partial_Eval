I once thought that Curv 0.5 had an interpreter and an SC compiler.
I now realize that it has two partial evaluators, and that both are naive
(both generate way too much code, and both can "diverge", generating
infinite code). I need to redesign the Curv core based on an understanding
of how "real" partial evaluators work.

The proposed new core has:
 * A pure interpreter that only works on "proper" values, not reactive values.
   It reduces an expression to a proper value.
 * A partial evaluator (SC, the shape compiler) that maps a set of parameters
   and an expression over those parameters onto a residual expression, at
   the same time lowering dynamically typed Curv to statically typed SubCurv.
    * If all parameters are static (constant values), then the SC behaves like
      the interpreter: the expression is evaluated as dynamically typed Curv,
      yielding a constant value as the result.
    * If all parameters are dynamic (opaque typed identifiers), then the
      expression is lowered to a SubCurv expression.
   In both cases, the "residual expression" that is generated includes a set
   of SubCurv bindings. Static function calls are simply evaluated by the
   interpreter and replaced by their result. Non-static calls to non-primitive
   functions cause the function to be compiled into SubCurv and added as a
   binding. The same function, when called with different argument types,
   is specialized into multiple definitions. Curv functions are naturally
   polymorphic, but SubCurv functions are statically typed, and each
   specialization has a different parameter type.
There is now only one partial evaluator, see [[Unify_PE_SC]].

Strawman goals:
* There is no blowup in code size due to unrolling loops or inlining function
  calls. It's impossible for the SC to diverge and generate infinite code.
  Functions are specialized only so that parameters have SC types. They aren't
  specialized finer than that (eg, so that a parameter is specialized to a
  numeric constant and disappears).
* In "normal" partial evaluators, the goal is to make a program run faster on
  the same platform. Here, the goal is evaluate as much of the code as possible
  on the CPU, leaving only code that depends on GPU-dynamic parameters as
  residual code.

Algorithm
---------
Offline for imperative code. Online for expressions and declarative generators.

In the SC, each expression has a phase:
 * Static: value known at SubCurv compile time.
 * Uniform: value known at beginning of frame in Viewer render loop,
   aka Shader Execution Start in WebGPU.
 * Dynamic: value varies per GPU shader thread.

FP In SubCurv
-------------
Assume #[...] is a lazy list.
  union shapes = make_shape {
    dist pt = min (map (s->s.dist pt) shapes);
    ... }
If shapes is a lazy list then any for loops in the list constructor
are executed on the GPU. Otherwise shapes is static & for loops are unrolled.

In many cases, shapes will have an SC tuple type.

Suppose map is builtin. In map::ir_call[f,list], f and list are IR expressions,
and the result is an IR list constructor expression (more abstract than GLSL
code). Here, f is a dynamic function. Suppose
 * list is an array.
   We generate a for loop over the array, producing an array of results.
 * list is a tuple.
   We unroll the loop and call different specializations of f on different
   list elements.
 * list is lazy. No need to construct a generator for the result list
   constructor, just use the generator given us.

No need for map to be builtin. Here's the current definition:
    map f list = [for (x in list) f x]
That's perfect. The above logic for constructing an IR list constructor
expression is taken care of by For_Stmt::ir_exec.

min is builtin. By default, min eagerly evaluates its argument, then iterates
over the elements of the resulting list (stored in GPU memory) to compute
the result. It can also optimize, with a special case when the argument is a
list constructor, in which case it avoids generating an intermediate list value
if it isn't a plex. This optimization is shared by all reduction operators
using shared code in Binary_Array_Op.

`reduce` should be builtin. The above is a complex optimization, I'm not sure
how to write a Curv definition of `reduce` that could be optimized this way.
(It requires a smart optimizing SC compiler which is nowhere near MVP.)

Partial Evaluation of Statements
--------------------------------
A do-expression is either fully evaluated to a Constant result,
or it is partially evaluated to a residual expression containing statements
and subexpressions that could not be fully evaluated.

Strawman implementation: offline PE. First, binding analysis.
  Given a do clause, all nonlocals are annotated as static (known constants)
  or dynamic. Within the statement list, all local variables are mutable
  (they are assigned to) or immutable. Immutable variables are static if their
  definiens are static. A mutable variable is dynamic if an RHS expression
  in an assignment to it is dynamic, OR IF it is assigned within control flow
  that depends on a dynamic variable.
Next, specialization.
  * If all local variables are static, then execute the statements.
    The residual is a set of static bindings.
  * If all local variables are dynamic, then compile the statement list
    into SubCurv without executing it.
  What if there is a mix of static and dynamic local variables?
  * Static immutable variables are only referenced in expressions, where they
    are substituted for their value when the expression is PE'ed.
  * If the first N top level statements in the statement list are static,
    then they can be executed statically and replaced by static bindings.
This meets requirements. No superfluous code bloat (eg I'm not using polyvariant
program point specialization to inline loops).

Partial Evaluation of Generators
--------------------------------
In a list contructor, the count must be known statically, and each list
element must have a subcurv type. This is trivially true if the list
constructor is fully static.

The generator within a list constructor must have a static count.
 * A compound generator a,b,c has a static count if each individual generator
   has a static count.
 * 'if (cond) gen' has a static count if 'cond' is static and gen has a static
   count.
 * 'if (cond) gen1 else gen2' has a static count if:
     * cond is static and the selected arm has a static count.
     * cond is dynamic and both arms have the same static count.
 * 'for (i in list) gen' has a static count if list has a subcurv array type
   and gen has a static count. (If list is static, that suffices, because a
   static list is guaranteed to have a subcurv array type. All static values
   have subcurv types.)
 * '... list' has a static count if 'list' has a subcurv type.

We want to support for loops over tuples. See 'FP in SubCurv'.

In a record constructor, all of the field names must be known statically,
and each field element must have a subcurv type.

In the future, a list constructor, that doesn't have a static count, and only
depends on uniform GPU variables (not non-uniform GPU variables), could be
executed on the CPU each time the uniform variable changes, and the resulting
list made available in a uniform buffer with a runtime-determined count.
In other cases, the list could be generated using an earlier compute shader
pipeline stage.

Partial Evaluation of Expressions
---------------------------------
Use online PE. Static function calls are replaced by their result.
Non-static function calls are not inlined. If the called function is
nonprimitive,
 * The function is specialized for the SC type of the actual argument
   and lowered to SubCurv. An auxiliary module-level binding is generated.
 * The specialization fails if the result does not have a subcurv type.
 * The function must not be recursive.

To PE an if-else expression,
 * When the condition is static, just PE the selected branch.
 * When the condition is dynamic, the then- and else- branches must
   both be partially evaluated, and the results must have the same SC type.
   This type constraint might be liftable using [[Union_Types]].

Imperative PE Research
----------------------
## Fortran
Partial Evaluation of Numerical Programs in Fortran
https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.495.4557&rep=rep1&type=pdf

They use offline partial evaluation. First, there is binding time analysis,
where every expression and statement is marked as static or dynamic, based
on data dependencies.

The specialization phase follows the annotations made by the binding-time
analysis: it executes static statements, reduces partially static expressions,
and specializes dynamic program points (functions, procedures, basic blocks).
During the specialization of a dynamic basic block the partial evaluator runs
through the sequence of statements step-by-step, executing static statements
and generating code for dynamic ones. When a dynamic conditional, e.g. an IF,
is met, both branches are specialized.

A polyvariant program point specialization is used for the specialization of
dynamic program points [9,15]: the same program point may be specialized with
respect to different static storages. Program point specialization includes
function and procedure specialization, and specialization of target points for
jumps. The specialization of dynamic functions and procedures is depth-first.
It is necessary to specialize a function or procedure before the statements
following the call are specialized, because of the effects a procedure or
function can have on the static storage. A done- and a pending-list are used
to keep track of already specialized program points and program points pending
to be specialized

Offline PE makes sense to me for imperative code. I can't fathom how online
PE would work for imperative. (Sakharov also says that offline is "considered
more appropriate for imperative".)

## Polyvariant Program Point Specialization
Used by [Fortran]. [Sakharov] warns may generate huge residual programs.

## Sakharov
Specialization of Imperative Programs Through Analysis of Relational Expressions
Alexander Sakharov
http://sakharov.net/download/lncs.pdf

^^ An offline PE that uses "advanced data flow analysis". It can reduce more
code statically than simpler algorithms:
  Expressions whose variables are not static can be classified as static by
this analysis.
  Analysis of relational expressions and other propositions expands partial
evaluation horizons: not only static values of variables but also other
assertions may serve as pre-conditions for partial evaluation

"Polyvariant program point specialization" (referenced by the Fortran paper)
can produce huge residual programs. Sakharov's technique generates smaller
programs. He uses a Control Flow Graph program representation. Curv has
exceptionally simple control flow graphs (no gotos, no loop breaks, no
return statement).

Functional PE Research
----------------------
Tutorial on Online Partial Evaluation
https://www.cs.utexas.edu/~wcook/tutorial/PEnotes.pdf

This tutorial suggests that on-line evaluation is simpler for pure functional
languages. It can also find more opportunities to reduce code.

* When an if-else condition is symbolic, the then- and else- branches must
  both be partially evaluated. This can cause divergence when the normal
  program would terminate, unless extra effort is made.
* Function calls and recursion cause extra complication.

The tutorial's initial 'naive' partial evaluator is like mine:
* When an if-else condition is symbolic, then partially evaluate both the
  then- and else- branches, and return a symbolic if expression.
* Non-primitive function calls are effectively inlined.
These two features mean that a recursive function can recurse forever,
if the termination condition remains symbolic in each recursive call.

Proper treatment of recursive functions requires from us to synthesize residual
programs instead of just residual expressions based on naive inlining.

When we call a non-primitive function, we generate a specialized version of
the function, and construct a symbolic call to the specialized version.
(We track if the required specialized version has already been generated
or if the generation is currently in progress.)
